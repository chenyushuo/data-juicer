{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68c73019",
   "metadata": {},
   "source": [
    "# Operator Insights\n",
    "\n",
    "Data-Juicer Operators (OPs) provide a variety of basic capabilities of data processing, including modification, cleaning, filtering and deduplication.\n",
    "\n",
    "For now, there are 5 types of OPs: Formatter, Mapper, Filter, Deduplicator, Selector.\n",
    "\n",
    "Formatters are used to discover, load, and canonicalize source data to Data-Juicer DJDataset or its subclass NestedDataset, which support several input data formats, such as csv/tsv, json/jsonl, parquet, doc, pdf, and plain-text format (e.g. txt, tex, code).\n",
    "\n",
    "The other 4 types of OPs are mainly for data processing.\n",
    "\n",
    "In this notebook, we focus on these 4 types of OPs. And in the following sections, we will run several Operators to gain a deeper understanding of OPs, and inspect their results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b5025a",
   "metadata": {},
   "source": [
    "## Mappers\n",
    "\n",
    "A Mapper is primarily used for editing, modifying, enhancing, or synthesizing data sample functionality.\n",
    "\n",
    "The basic class of Mapper is like:\n",
    "```python\n",
    "class Mapper(OP):\n",
    "    ...\n",
    "    def process(self, sample: Dict) -> Dict:\n",
    "        # process a single sample\n",
    "        ...\n",
    "\n",
    "    def run(self, dataset: DJDataset) -> DJDataset:\n",
    "        return dataset.map(self.process, **args)\n",
    "    ...\n",
    "```\n",
    "\n",
    "It needs a `process` method to process a single sample. In the unified `run` method, Mapper just processes each sample in the dataset with the `map` method of DJDataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea2d771",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "For example, we can use `CleanIpMapper` to clean up IP addresses in text.\n",
    "\n",
    "First, we import this OP from Data-Juicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fb13c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data_juicer.ops.mapper.clean_ip_mapper import CleanIpMapper\n",
    "op = CleanIpMapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3348e4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Then, we can apply this OP in two ways.\n",
    "\n",
    "-  Invoke OP's process directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17e3dd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'test of ip '}\n"
     ]
    }
   ],
   "source": [
    "sample = {'text': 'test of ip 11.22.33.44'}\n",
    "out_sample = op.process(sample)\n",
    "\n",
    "print(out_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfacf3a",
   "metadata": {},
   "source": [
    "-  Invoke OP's process with NestedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "069f2c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 555.17 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'test of ip '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from data_juicer.core import NestedDataset\n",
    "\n",
    "samples = [{'text': 'test of ip 11.22.33.44'}]\n",
    "ds = NestedDataset.from_list(samples)\n",
    "out_ds = ds.map(op.process) \n",
    "\n",
    "for sample in out_ds:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ccc00c-c785-4787-9519-0e9cf2a98463",
   "metadata": {},
   "source": [
    "You can also invoke `run` method directly on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41fe37d6-6c3e-4b82-9459-a52e05159796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n",
      "clean_ip_mapper_process: 100%|██████████| 1/1 [00:00<00:00, 743.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'test of ip '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out_ds = op.run(ds)\n",
    "\n",
    "for sample in out_ds:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feaf200",
   "metadata": {},
   "source": [
    "## Filters\n",
    "\n",
    "A Filter is mainly used to filter out unexpected samples, such as low-quality, NSFW samples, or filter according to some statistics (we call it \"stats\").\n",
    "\n",
    "The basic class of Filter is like:\n",
    "```python\n",
    "class Filter(OP):\n",
    "    ...\n",
    "    def compute_stats(self, sample: Dict) -> Dict:\n",
    "        # compute stats of a single sample\n",
    "        ...\n",
    "    \n",
    "    def process(self, sample: Dict) -> bool:\n",
    "        # decide whether to keep this single sample\n",
    "        ...\n",
    "\n",
    "    def run(self, dataset: DJDataset) -> DJDataset:\n",
    "        return dataset.map(self.compute_stats, **args)\n",
    "                      .filter(self.process, **args)\n",
    "    ...\n",
    "```\n",
    "It needs a `compute_stats` method to compute the statistics we are interested in, such as the number of words, image-text similarity, video motion scores, etc. The `process` method is also required. But different from Mappers, this method here is used to decide whether to keep a single sample according to their computed stats and predefined thresholds. As a result, the implementation of the `run` method of Filters is to compute stats for each sample in the dataset and then to filter out those unexpected samples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec25e214",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Here we show you how to use `WordsNumFilter` to filter out samples whose number of words is not within the range of [3, 10], which means, to discard samples with less than 3 or more than 10 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6f9f55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', '__dj__stats__'],\n",
      "    num_rows: 2\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from data_juicer.core import NestedDataset\n",
    "\n",
    "samples = [\n",
    "    {'text': 'Data Juicer'}, \n",
    "    {'text': 'Welcome to Data Juicer Playground'}\n",
    "]\n",
    "ds = NestedDataset.from_list(samples)\n",
    "\n",
    "# Add a new column to the dataset to store the stats of the Filter operator.\n",
    "from data_juicer.utils.constant import Fields\n",
    "ds = ds.add_column(name=Fields.stats, column=[{}] * ds.num_rows)\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f068ca7b-42b3-4a8d-8c81-f6209ec09f7c",
   "metadata": {},
   "source": [
    "Then we initialize this Filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dde50a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_juicer.ops.filter.words_num_filter import WordsNumFilter\n",
    "op = WordsNumFilter(\n",
    "    min_num=3, \n",
    "    max_num=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ade25c-26f5-4630-acbc-6f9c40eab583",
   "metadata": {},
   "source": [
    "Finally, we just need to compute stats for each sample and then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55c07c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2/2 [00:00<00:00, 700.74 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Data Juicer', '__dj__stats__': {'num_words': 2}}\n",
      "{'text': 'Welcome to Data Juicer Playground', '__dj__stats__': {'num_words': 5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 2/2 [00:00<00:00, 1072.85 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', '__dj__stats__'],\n",
      "    num_rows: 1\n",
      "})\n",
      "Number of samples of output dataset : 1\n",
      "{'text': 'Welcome to Data Juicer Playground', '__dj__stats__': {'num_words': 5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds_stats = ds.map(op.compute_stats)\n",
    "\n",
    "for sample in ds_stats:\n",
    "    print(sample)\n",
    "\n",
    "out_ds = ds_stats.filter(op.process)\n",
    "\n",
    "print(out_ds)\n",
    "print(f'Number of samples of output dataset : {len(out_ds)}')\n",
    "for sample in out_ds:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad05a3-af38-4a38-a6ac-9e9436ed67b7",
   "metadata": {},
   "source": [
    "Same as Mappers, you can also invoke the `run` method directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc17557e-a86d-42b7-8074-e912bdbb906f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 2. Reducing num_proc to 2 for dataset of size 2.\n",
      "words_num_filter_compute_stats (num_proc=2): 100%|██████████| 2/2 [00:00<00:00, 20.13 examples/s]\n",
      "num_proc must be <= 2. Reducing num_proc to 2 for dataset of size 2.\n",
      "words_num_filter_process (num_proc=2): 100%|██████████| 2/2 [00:00<00:00, 25.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', '__dj__stats__'],\n",
      "    num_rows: 1\n",
      "})\n",
      "Number of samples of output dataset : 1\n",
      "{'text': 'Welcome to Data Juicer Playground', '__dj__stats__': {'num_words': 5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out_ds = op.run(ds)\n",
    "\n",
    "print(out_ds)\n",
    "print(f'Number of samples of output dataset : {len(out_ds)}')\n",
    "for sample in out_ds:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ce063e",
   "metadata": {},
   "source": [
    "## Deduplicators\n",
    "\n",
    "A Deduplicator is mainly used to detect and remove duplicate or near-duplicate samples from datasets.\n",
    "\n",
    "The basic class of Deduplicator is like:\n",
    "```python\n",
    "class Deduplicator(OP):\n",
    "    ...\n",
    "    def compute_hash(self, sample: Dict) -> Dict:\n",
    "        # compute the hash of a single sample\n",
    "        ...\n",
    "    \n",
    "    def process(self, dataset: DJDataset) -> DJDataset:\n",
    "        # deduplicate for the dataset\n",
    "        ...\n",
    "\n",
    "    def run(self, dataset: DJDataset) -> DJDataset:\n",
    "        dataset = dataset.map(self.compute_hash, **args)\n",
    "        return self.process(dataset)\n",
    "    ...\n",
    "```\n",
    "\n",
    "Similar to Filter, it needs to compute the hash values for each sample in `compute_hash` method and then apply the deduplication process for the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4370da",
   "metadata": {},
   "source": [
    "Here is a case-insensitive demo to deduplicate samples using exact matching (md5 hash) from `DocumentDeduplicator` OP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1391e28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 2\n",
      "})\n",
      "Number of samples of input dataset : 2\n"
     ]
    }
   ],
   "source": [
    "from data_juicer.core import NestedDataset\n",
    "\n",
    "samples = [\n",
    "    {'text': 'welcome to data juicer playground'}, \n",
    "    {'text': 'Welcome to Data Juicer Playground'}\n",
    "]\n",
    "ds = NestedDataset.from_list(samples)\n",
    "\n",
    "print(ds)\n",
    "print(f'Number of samples of input dataset : {len(ds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5197172-b9f3-406b-ab4f-5a218ecd74c9",
   "metadata": {},
   "source": [
    "We initialize a Deduplicator first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4af63594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_juicer.ops.deduplicator.document_deduplicator import DocumentDeduplicator\n",
    "op = DocumentDeduplicator(lowercase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1263955e-e3f0-4032-874d-bfd9ef8b983e",
   "metadata": {},
   "source": [
    "Then we run these two methods for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b09cc3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2/2 [00:00<00:00, 1023.38 examples/s]\n",
      "Filter: 100%|██████████| 2/2 [00:00<00:00, 1433.46 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', '__dj__hash'],\n",
      "    num_rows: 1\n",
      "})\n",
      "Number of samples of output dataset : 1\n",
      "{'text': 'welcome to data juicer playground', '__dj__hash': 'f2fea8ead9b37a9f9085037a8d97d497'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds_with_hash = ds.map(op.compute_hash)\n",
    "out_ds, dup_pairs= op.process(ds_with_hash, show_num=1)\n",
    "\n",
    "print(out_ds)\n",
    "print(f'Number of samples of output dataset : {len(out_ds)}')\n",
    "for sample in out_ds:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f96f498",
   "metadata": {},
   "source": [
    "Here `dup_pairs` is the duplicate pairs obtained from the Tracer tool, which will be introduced later. We can print it to find out the duplicate pairs to check if it works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "203f4b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplicate hash value : f2fea8ead9b37a9f9085037a8d97d497\n",
      "{'text': 'welcome to data juicer playground', '__dj__hash': 'f2fea8ead9b37a9f9085037a8d97d497'}\n",
      "{'text': 'Welcome to Data Juicer Playground', '__dj__hash': 'f2fea8ead9b37a9f9085037a8d97d497'}\n"
     ]
    }
   ],
   "source": [
    "for key, dup_pair in dup_pairs.items():\n",
    "    print(f'Deduplicate hash value : {key}')\n",
    "    for sample in dup_pair:\n",
    "        print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e6fb20",
   "metadata": {},
   "source": [
    "## Selectors\n",
    "\n",
    "A Selector is mainly used to select top samples based on ranking. It is primarily used to perform statistical analysis on a specific field of a dataset. For instance, it can select the top k samples with the highest frequency, or to choose a portion of samples with the highest proportion.\n",
    "\n",
    "The basic class of Selector is like:\n",
    "```python\n",
    "class Selector(OP):\n",
    "    ...\n",
    "    def process(self, sample: Dict) -> Dict:\n",
    "        # select from the whole dataset\n",
    "        ...\n",
    "\n",
    "    def run(self, dataset: DJDataset) -> DJDataset:\n",
    "        return self.process(dataset)\n",
    "    ...\n",
    "```\n",
    "\n",
    "It's quite similar to Mapper but selects target samples from the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65069e05",
   "metadata": {},
   "source": [
    "Here is an example. First we construct a dataset with 5 samples, and use Selector operator to select the top 2 samples based on `meta.count`. It's worth noticing that Data-Juicer support '.' operator to access the nested fields in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15d9f228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'meta'],\n",
      "    num_rows: 5\n",
      "})\n",
      "Number of samples of input dataset : 5\n"
     ]
    }
   ],
   "source": [
    "from data_juicer.core import NestedDataset\n",
    "\n",
    "samples = [{\n",
    "            'text': 'Today is Sun', \n",
    "            'meta': {'count': 5 }\n",
    "        }, {\n",
    "            'text': 'a v s e c s f e f g a a a  ',\n",
    "            'meta': {'count': 23 }\n",
    "        }, {\n",
    "            'text': '，。、„”“«»１」「《》´∶：？！',\n",
    "            'meta': { 'count': 48 }\n",
    "        }, {\n",
    "            'text': '他的英文名字叫Harry Potter',\n",
    "            'meta': { 'count': 78 }\n",
    "        }, {\n",
    "            'text': '这是一个测试',\n",
    "            'meta': { 'count': 3 }\n",
    "        }]\n",
    "ds = NestedDataset.from_list(samples)\n",
    "\n",
    "print(ds)\n",
    "print(f'Number of samples of input dataset : {len(ds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df53727-7fad-4f26-b3cb-a98305d16297",
   "metadata": {},
   "source": [
    "Initialize a `TopkSpecifiedFieldSelector` and specify the target key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e06c5094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_juicer.ops.selector.topk_specified_field_selector import TopkSpecifiedFieldSelector\n",
    "op = TopkSpecifiedFieldSelector(field_key='meta.count', topk=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c197391f-4282-4c69-a2d8-28caa489f5bb",
   "metadata": {},
   "source": [
    "Select top-k samples from the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "371439e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'meta'],\n",
      "    num_rows: 2\n",
      "})\n",
      "Number of samples of output dataset : 2\n",
      "{'text': '他的英文名字叫Harry Potter', 'meta': {'count': 78}}\n",
      "{'text': '，。、„”“«»１」「《》´∶：？！', 'meta': {'count': 48}}\n"
     ]
    }
   ],
   "source": [
    "out_ds = op.process(ds)\n",
    "\n",
    "print(out_ds)\n",
    "print(f'Number of samples of output dataset : {len(out_ds)}')\n",
    "for sample in out_ds:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5fd935",
   "metadata": {},
   "source": [
    "## Multimodel Demos\n",
    "\n",
    "Data-Juicer now supplies a lot of operators to process **multimodal** data. Here we provide a few demos to show you how to process multimodal datasets.\n",
    "\n",
    "**Note**\n",
    "\n",
    "The input dataset must adhere to the Data-Juicer format, characterized by a text-centric, multi-chunk structure interspersed with special tokens. \n",
    "\n",
    "Additionally, we offer a suite of multimodal tools designed to facilitate conversion between other formats and the Data-Juicer format. We will dive into the detail of this format and corresponding conversion tools in the next notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1526f6ef",
   "metadata": {},
   "source": [
    "We use the test dataset from Data-Juicer in `{data-juicer_root}/tests/ops/data` to show you how to construct your dataset and process multimodel data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caabde9",
   "metadata": {},
   "source": [
    "### Image-Text Dataset\n",
    "\n",
    "Generally speaking, most multimodal datasets consist of at least two modalities, such as image-text pairs.\n",
    "\n",
    "We construct an image-text dataset first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b85859f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'images', '__dj__stats__'],\n",
      "    num_rows: 2\n",
      "})\n",
      "Number of samples of input dataset : 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from data_juicer.core import NestedDataset\n",
    "from data_juicer.utils.mm_utils import SpecialTokens\n",
    "\n",
    "data_juicer_root = '../'  # change this path to your data-juicer root\n",
    "\n",
    "data_path = f'{data_juicer_root}/tests/ops/data'\n",
    "cat_path = os.path.join(data_path, 'cat.jpg')\n",
    "\n",
    "# we need a spacial token to indicate the position of multimodal data in the text.\n",
    "samples = [{\n",
    "            'text': f'{SpecialTokens.image}a photo of a cat',  # 0.2457006871700287\n",
    "            'images': [cat_path]\n",
    "        }, {\n",
    "            'text': f'{SpecialTokens.image}a photo of a dog',  # 0.19304907321929932\n",
    "            'images': [cat_path]\n",
    "        }]\n",
    "ds = NestedDataset.from_list(samples)\n",
    "\n",
    "# add a new column to the dataset to store the statistical values of the filter operator.\n",
    "from data_juicer.utils.constant import Fields\n",
    "ds = ds.add_column(name=Fields.stats, column=[{}] * ds.num_rows)\n",
    "\n",
    "print(ds)\n",
    "print(f'Number of samples of input dataset : {len(ds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7308f2bb",
   "metadata": {},
   "source": [
    "Here we use `ImageTextSimilarityFilter` to filter out the samples whose image-text pair is not aligned well.\n",
    "\n",
    "During the initialization of `ImageTextSimilarityFilter` operator, we need to load the `openai/clip-vit-base-patch32` model. You can also replace this HuggingFace Hub model path with a local model path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d526e147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python310/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/python310/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from data_juicer.ops.filter.image_text_similarity_filter import ImageTextSimilarityFilter\n",
    "op = ImageTextSimilarityFilter(\n",
    "    hf_clip = 'openai/clip-vit-base-patch32',  # you can replace it with a local model path\n",
    "    min_score=0.2,\n",
    "    max_score=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea34ce87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2/2 [00:00<00:00,  4.26 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '<__dj__image>a photo of a cat', 'images': ['../data-juicer/tests/ops/data/cat.jpg'], '__dj__stats__': {'image_text_similarity': [0.24569691717624664]}}\n",
      "{'text': '<__dj__image>a photo of a dog', 'images': ['../data-juicer/tests/ops/data/cat.jpg'], '__dj__stats__': {'image_text_similarity': [0.19304543733596802]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 2/2 [00:00<00:00, 1240.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'images', '__dj__stats__'],\n",
      "    num_rows: 1\n",
      "})\n",
      "Number of samples of output dataset : 1\n",
      "{'text': '<__dj__image>a photo of a cat', 'images': ['../data-juicer/tests/ops/data/cat.jpg'], '__dj__stats__': {'image_text_similarity': [0.24569691717624664]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds_with_stats = ds.map(op.compute_stats)\n",
    "\n",
    "for sample in ds_with_stats:\n",
    "    print(sample)\n",
    "\n",
    "out_ds = ds_with_stats.filter(op.process)\n",
    "\n",
    "print(out_ds)\n",
    "print(f'Number of samples of output dataset : {len(out_ds)}')\n",
    "for sample in out_ds:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fdcad1",
   "metadata": {},
   "source": [
    "### Image-Only Dataset\n",
    "\n",
    "Sometimes we may want to process datasets based on a single modality or work with single-modal datasets.\n",
    "\n",
    "Here we take `ImageShapeFilter` as example to process image-only dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "269b79cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['images', '__dj__stats__'],\n",
      "    num_rows: 3\n",
      "})\n",
      "Number of samples of input dataset : 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import Dataset\n",
    "\n",
    "data_juicer_root = '../'  # change this path to your data-juicer root\n",
    "\n",
    "data_path = f'{data_juicer_root}/tests/ops/data'\n",
    "img1_path = os.path.join(data_path, 'img1.png') # 336*336\n",
    "img2_path = os.path.join(data_path, 'img2.jpg') # 640*480\n",
    "img3_path = os.path.join(data_path, 'img3.jpg') # 342*500\n",
    "\n",
    "samples = [{\n",
    "            'images': [img1_path]\n",
    "        }, {\n",
    "            'images': [img2_path]\n",
    "        }, {\n",
    "            'images': [img3_path]\n",
    "        }]\n",
    "ds = Dataset.from_list(samples)\n",
    "\n",
    "# add a new column to the dataset to store the statistical values of the filter operator.\n",
    "from data_juicer.utils.constant import Fields\n",
    "ds = ds.add_column(name=Fields.stats, column=[{}] * ds.num_rows)\n",
    "\n",
    "print(ds)\n",
    "print(f'Number of samples of input dataset : {len(ds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f688478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_juicer.ops.filter.image_shape_filter import ImageShapeFilter\n",
    "op = ImageShapeFilter(\n",
    "    min_width=400, \n",
    "    min_height=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93aea41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3/3 [00:00<00:00, 352.96 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': ['../data-juicer/tests/ops/data/img1.png'], '__dj__stats__': {'image_height': [336], 'image_width': [336]}}\n",
      "{'images': ['../data-juicer/tests/ops/data/img2.jpg'], '__dj__stats__': {'image_height': [480], 'image_width': [640]}}\n",
      "{'images': ['../data-juicer/tests/ops/data/img3.jpg'], '__dj__stats__': {'image_height': [500], 'image_width': [342]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 3/3 [00:00<00:00, 1489.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['images', '__dj__stats__'],\n",
      "    num_rows: 1\n",
      "})\n",
      "Number of samples of output dataset : 1\n",
      "{'images': ['../data-juicer/tests/ops/data/img2.jpg'], '__dj__stats__': {'image_height': [480], 'image_width': [640]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds = ds.map(op.compute_stats)\n",
    "\n",
    "for sample in ds:\n",
    "    print(sample)\n",
    "\n",
    "out_ds = ds.filter(op.process)\n",
    "\n",
    "print(out_ds)\n",
    "print(f'Number of samples of output dataset : {len(out_ds)}')\n",
    "for sample in out_ds:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5f4725",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this notebook, we take a look at the basic 5 types of OPs in Data-Juicer. For each type of OP, we take an OP example to show how to process dataset with them. Finally, we provide two demos to show the processing capabilities on multimodal datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
